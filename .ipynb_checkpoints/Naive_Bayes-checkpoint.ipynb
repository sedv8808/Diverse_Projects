{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 571 lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree \n",
    "from ipy_table import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "rubric={mechanics:2}\n",
    "\n",
    "Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "The learning objectives of this lab are:\n",
    "1. to learn how to use common evaluation metrics used in machine learning\n",
    "2. to understand the Naive Bayes algorithm and how to use it with `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Precision and recall \"by hand\"\n",
    "rubric={reasoning:4}\n",
    "\n",
    "\n",
    "Below is the confusion matrix of a machine learning system that predicts whether a cancer is malignant or not. \n",
    "\n",
    "|    Actual      | Predicted Benign | Predicted Malignant |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual Benign**       | 438 | 6 |\n",
    "| **Actual Malignant**       | 50 | 194 |\n",
    "\n",
    "1. What is the accuracy of the classifier? \n",
    "2. What are the precision and recall? \n",
    "3. Discuss which evaluation metric would be more informative in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:** \n",
    "1. Accuracy = (194 + 438)/(194 + 438 + 50 + 6) = 0.91\n",
    "2. Precision = TP / (TP + FP) = 194 / (194 + 6) = 0.97<br>\n",
    "Recall = TP/(TP + FN) = 194 / (194 + 50) = 0.79\n",
    "3. Precision and recall would be more informative in this case because \n",
    "    - The data is unbalanced with respect to the labels; there are many more benign cases compared to malignant cases.\n",
    "    - Although the system is _precise_ in identifying malignant cases, it has a low recall; it misses many such cases. Accuracy does not tell the whole story in this case. In particular, it does not convey the information that the system mislabels many malignant cases as benign.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Naive Bayes \"by hand\"\n",
    "\n",
    "Consider the dataset below, which has $10$ training examples and $3$ features:\n",
    "\n",
    "$$X = \\begin{bmatrix}0 & 0 & 1\\\\0 & 1 & 1\\\\ 0 & 1 & 1\\\\ 1 & 1 & 0\\\\0 & 1 & 0\\\\0 & 1 & 1\\\\1 & 0 & 0\\\\1 & 1 & 0\\\\1 & 0 & 1\\\\1 & 0 & 0\\\\\\end{bmatrix}, \\quad y = \\begin{bmatrix}\\text{spam}\\\\\\text{spam}\\\\\\text{spam}\\\\\\text{spam}\\\\\\text{spam}\\\\\\text{spam}\\\\\\text{not spam}\\\\\\text{not spam}\\\\\\text{not spam}\\\\\\text{not spam}\\end{bmatrix}$$\n",
    "\n",
    "The feature in the first column is `<your name>` (whether the e-mail contained your name), in the second column is \"pharmaceutical\" (whether the e-mail contained this word), and the third column is \"PayPal\" (whether the e-mail contained this word).\n",
    "Suppose you believe that a naive Bayes model would be appropriate for this dataset, and you want to classify the following test example:\n",
    "\n",
    "$$\\hat{x} = \\begin{bmatrix}1 & 1 & 0\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a) Prior probabilities\n",
    "rubric={raw:2}\n",
    "\n",
    "Compute the estimates of the class prior probabilities (you don't need to show any work):\n",
    "1. $p(\\text{spam})$.\n",
    "2. $p(\\text{not spam})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:** $6/10$, $4/10$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(b) Conditional probabilities\n",
    "rubric={raw:6}\n",
    "\n",
    "Compute the estimates of the 6 conditional probabilities required by naive Bayes for this example (you don't need to show any work):\n",
    "\n",
    "1. $p(\\text{your name} = 1  \\mid \\text{spam})$.\n",
    "2. $p(\\text{pharmaceutical} = 1 \\mid \\text{spam})$.\n",
    "3. $p(\\text{PayPal} = 0  \\mid \\text{spam})$.\n",
    "4. $p(\\text{your name} = 1  \\mid \\text{not spam})$\n",
    "5. $p(\\text{pharmaceutical} = 1  \\mid \\text{not spam})$.\n",
    "6. $p(\\text{PayPal} = 0  \\mid \\text{not spam})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:** 1/6, 5/6, 2/6, 1, 1/4, 3/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(c) Prediction\n",
    "rubric={reasoning:4}\n",
    "\n",
    "Under the naive Bayes model and your estimates of the above probabilities, what is the most likely label for the test example? (Show your work.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$p(\\text{spam} \\mid x_1 = 1, x_2 = 1, x_3 = 0) \\propto p( x_1 = 1, x_2 = 1, x_3 = 0 \\mid \\text{spam})p(\\text{spam}) $$\n",
    "\n",
    "$$ = p(x_1 = 1\\mid \\text{spam})p(x_2 = 1 \\mid \\text{spam})p(x_3 = 0 \\mid \\text{spam})p(\\text{spam})$$\n",
    "\n",
    "$$ = (1/6)(5/6)(2/6)(6/10) $$\n",
    "\n",
    "$$\\approx 0.028 $$\n",
    "\n",
    "And\n",
    "\n",
    "$$p(\\text{not spam} \\mid  x_1 = 1, x_2 = 1, x_3 = 0) \\propto p( x_1 = 1, x_2 = 1, x_3 = 0 \\mid \\text{not spam})p(\\text{not spam}) $$\n",
    "\n",
    "$$ = p(x_1 = 1 \\mid \\text{not spam})p(x_2 = 1 \\mid \\text{not spam})p(x_3 = 0 \\mid \\text{not spam})p(\\text{not spam})  $$\n",
    "\n",
    "$$ = (1)(1/4)(3/4)(4/10) $$\n",
    "\n",
    "$$ \\approx 0.075.$$\n",
    "\n",
    "Since $p(\\text{not spam} \\mid  x_1 = 1, x_2 = 1, x_3 = 0)$ is proportional to a bigger number, and the proportionality constants are the same $(p(x_1=1,x_2=1,x_3=0))$, we would predict \"not spam\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 2(d) Laplace smoothing\n",
    "rubric={reasoning:1}\n",
    "\n",
    "One way to think of Laplace smoothing is that you're augmenting the training set with extra counts. Consider the estimates of the conditional probabilities in this dataset when we use Laplace smoothing (with $\\beta = 1$). Give a set of extra training examples that we could add to the original training set that would make the basic estimates give us the estimates with Laplace smoothing. In other words give a set of extra training examples that, if they were included in the training set and we didn't use Laplace smoothing, would give the same estimates of the conditional probabilities as using the original dataset with Laplace smoothing.\n",
    "Present your answer in a reasonably easy-to-read format, for example the same format as the data set at the start of this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "You could add the following examples:\n",
    "\n",
    "$$X_\\beta = \\begin{bmatrix}0 & 0 & 0\\\\ 0 & 0 & 0 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1\\end{bmatrix}, \\quad y_\\beta = \\begin{bmatrix}0 \\\\ 1 \\\\ 1 \\\\ 0\\end{bmatrix}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Naive Bayes for sentiment analysis\n",
    "\n",
    "Naive Bayes is popular in text classification tasks. In this exercise you will use \n",
    "[multinomial Naive Bayes algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) as implemented in `scikit-learn` for a text classification task called [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis), which is a problem of assigning positive or negative label to a text based on the sentiment or attitude expressed in  it. \n",
    "\n",
    "You will use [IMDB movie review data set](https://www.kaggle.com/utathya/imdb-review-dataset) for this exercise. \n",
    "\n",
    "Download the CSV using the above link and unzip it. Please _do not commit the CSV to GitHub_ as it is very large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(a) Loading data and preprocessing\n",
    "rubric={accuracy:2}\n",
    "\n",
    "1. Open the data CSV as a pandas DataFrame. (Hint: Use the `encoding` argument to open the CSV with the right encoding.)\n",
    "2. There are three possible labels in the dataset: `pos`, `neg`, and `unsup`. Discard rows with `unsup` label from the dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df = pd.read_csv('imdb_master.csv', encoding = \"ISO-8859-1\")\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unsup    50000\n",
       "neg      25000\n",
       "pos      25000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# only consider positive and negative reviews\n",
    "imdb_df = imdb_df[imdb_df['label'].str.startswith(('pos','neg'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(b) Feature extraction\n",
    "rubric={accuracy:4,quality:2}\n",
    "\n",
    "The current data is in the form of moview reviews (text paragraphs) and their targets (`pos` or `neg`). \n",
    "You need to encode movie reviews into feature vectors so that you can train supervised machine learning models with `scikit-learn`. In this exercise you will do this in two different ways. \n",
    "\n",
    "#### Create word frequency counts (`X_counts`)\n",
    "Turn the text into sparse vector of word frequency counts using [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) from  `scikit-learn`. Note that this may take a while to run, as you'll be dealing with ~50,000 movie reviews. Optionally, explore the arguments of `CountVectorizer` (e.g., [`stop_words`](https://scikit-learn.org/stable/modules/feature_extraction.html#stop-words), `ngram_range`, `max_features`, `min_df`, and `tokenizer`).  \n",
    "\n",
    "#### Create binarized representation of words (`X_binary`)\n",
    "Create binarized encoding (`X_binary`) of `X_counts`, where you replace word frequencies $\\geq$ 1 by 1.    \n",
    "The intuition behind using binarized representation is that for sentiment analysis word occurrence may matter more than word frequency. For instance, the occurrence of the word _excellent_ tells us a lot and the fact that it occurs four times may not tell us much more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For tokenization\n",
    "import nltk\n",
    "# For converting words into frequency counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# initialize movie_vector object and then turn movie reviews train data into a vector \n",
    "movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize, stop_words='english')\n",
    "\n",
    "# use top 5000 words only\n",
    "# movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize, max_features = 5000) \n",
    "X_counts = movie_vec.fit_transform(imdb_df['review'])\n",
    "\n",
    "# Convert raw frequency counts into binarized representation. \n",
    "X_binary = X_counts > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(c) Train Naive Bayes classifier\n",
    "rubric={accuracy:4,quality:2,reasoning:2}\n",
    "\n",
    "1. Split (`X_counts`, `imdb_df.label`) into train (80%) and test (20%).\n",
    "2. Train [multinomial Naive Bayes algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) on the train set. \n",
    "3. Report train and test accuracies.\n",
    "4. Now repeat steps 1, 2, and 3 with (`X_binary`, `imdb_df.label`). \n",
    "5. Compare your results for `X_counts` and `X_binary` and note your observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_NB_train_test_accuracies(X, y, classifier = 'multinominal'):\n",
    "    \"\"\"\n",
    "    Given X, y, and the classifier, this function splits the \n",
    "    data into train and test splits, prints the train and test accuracies,\n",
    "    and returns the model.     \n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.20, \n",
    "                                                        random_state = 12)\n",
    "    if classifier.startswith('multinominal'):\n",
    "        model = MultinomialNB().fit(X_train, y_train)\n",
    "    elif classifier.startswith('bernoulli'):\n",
    "        model = BernoulliNB().fit(X_train, y_train)\n",
    "    print('Training accuracy:', model.score(X_train, y_train))\n",
    "    print('Test accuracy: ', model.score(X_test, y_test))\n",
    "    print('---------')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on binarized encoding \n",
      "Training accuracy: 0.9013\n",
      "Test accuracy:  0.8567\n",
      "---------\n",
      "Evaluation on counts encoding \n",
      "Training accuracy: 0.899075\n",
      "Test accuracy:  0.8555\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation on binarized encoding ')\n",
    "model_binary = get_NB_train_test_accuracies(X_binary, imdb_df.label, classifier = 'bernoulli')\n",
    "\n",
    "print('Evaluation on counts encoding ')\n",
    "model_counts = get_NB_train_test_accuracies(X_counts, imdb_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "\n",
    "For this dataset and with the specific `CountVectorizer` parameters used, we do not observe much difference between the test accuracies when word counts features were used vs. when word presence/absence features were used.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 3(d) Test your model on fake reviews \n",
    "rubric={reasoning:1}\n",
    "\n",
    "Test your model on fake movie reviews. Some examples are given below. Add to this list, predict using the trained model, and note your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fake_reviews = ['This movie was excellent! The performances were oscar-worthy!',\n",
    "               'Unbelievably disappointing.', \n",
    "               'Full of zany characters and richly applied satire, and some great plot twists',\n",
    "               'This is the greatest screwball comedy ever filmed',\n",
    "               'It was pathetic. The worst part about it was the boxing scenes.', \n",
    "               '''It could have been a great movie. It could have been excellent, \n",
    "                and to all the people who have forgotten about the older, \n",
    "                greater movies before it, will think that as well. \n",
    "                It does have beautiful scenery, some of the best since Lord of the Rings. \n",
    "                The acting is well done, and I really liked the son of the leader of the Samurai.\n",
    "                He was a likeable chap, and I hated to see him die...\n",
    "                But, other than all that, this movie is nothing more than hidden rip-offs.\n",
    "                '''\n",
    "              ]\n",
    "gold_labels = ['pos', 'neg', 'pos', 'pos', 'neg', 'neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create word count encoding of the reviews.  \n",
    "fake_reviews_counts = movie_vec.transform(fake_reviews)\n",
    "fake_reviews_binary = fake_reviews_counts > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the Naive Bayes classifier\n",
    "predictions = model_binary.predict(fake_reviews_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos', 'neg', 'pos', 'pos', 'neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(predictions.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gold labels</th>\n",
       "      <th>NB labels</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>This movie was excellent! The performances were oscar-worthy!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>Unbelievably disappointing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>Full of zany characters and richly applied satire, and some great plot twists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>This is the greatest screwball comedy ever filmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>It was pathetic. The worst part about it was the boxing scenes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>It could have been a great movie. It could have been excellent, \\n                and to all the people who have forgotten about the older, \\n                greater movies before it, will think that as well. \\n                It does have beautiful scenery, some of the best since Lord of the Rings. \\n                The acting is well done, and I really liked the son of the leader of the Samurai.\\n                He was a likeable chap, and I hated to see him die...\\n                But, other than all that, this movie is nothing more than hidden rip-offs.\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gold labels NB labels  \\\n",
       "0  pos         pos        \n",
       "1  neg         neg        \n",
       "2  pos         pos        \n",
       "3  pos         pos        \n",
       "4  neg         neg        \n",
       "5  neg         pos        \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Review  \n",
       "0  This movie was excellent! The performances were oscar-worthy!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "1  Unbelievably disappointing.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "2  Full of zany characters and richly applied satire, and some great plot twists                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "3  This is the greatest screwball comedy ever filmed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "4  It was pathetic. The worst part about it was the boxing scenes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "5  It could have been a great movie. It could have been excellent, \\n                and to all the people who have forgotten about the older, \\n                greater movies before it, will think that as well. \\n                It does have beautiful scenery, some of the best since Lord of the Rings. \\n                The acting is well done, and I really liked the son of the leader of the Samurai.\\n                He was a likeable chap, and I hated to see him die...\\n                But, other than all that, this movie is nothing more than hidden rip-offs.\\n                  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 0)\n",
    "d = {'Review':fake_reviews, 'Gold labels':gold_labels, 'NB labels':predictions}\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: \n",
    "1. Works fairly well when there are clear words indicating whether the review is positive or negative, as the features we are using are word features.\n",
    "2. Fails for more complex examples, where understanding the context and overall text is essential to correctly classify reviews. The last example has many positive words in the beginning but the last sentence negates all positivity in the previous text. We need to incorporate deeper linguistic knowledge to correctly classify such cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Precision, recall, ROC, AUC using `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4(a) \n",
    "rubric={accuracy:4,quality:2,reasoning:2} \n",
    "\n",
    "1. Split (`X_binary`, `imdb_df.label`) into train (80%) and test (20%). Train multinomial Naive Bayes algorithm on the train set.\n",
    "2. Get [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) on the test portion and calculate precision and recall using the appropriate formulae.\n",
    "3. Now get precision and recall numbers using [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) on the test portion and cross-check your numbers with the numbers in this report.\n",
    "4. Plot an [ROC curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html). Report [AUC score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html). \n",
    "5. Briefly discuss and compare scores you got with different evaluation metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9013\n",
      "Test accuracy:  0.8567\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_binary, \n",
    "                                                    imdb_df.label, \n",
    "                                                    test_size = 0.20, \n",
    "                                                    random_state = 12)\n",
    "\n",
    "# Train a Multinomial Naive Bayes classifier\n",
    "model = BernoulliNB().fit(X_train, y_train)\n",
    "print('Training accuracy:', model.score(X_train, y_train))\n",
    "print('Test accuracy: ', model.score(X_test, y_test))\n",
    "print('---------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "predictions = list(model.predict(X_test))\n",
    "true_labels = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.877956081081081\n",
      "Recall:  0.829443447037702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "TN, FP, FN, TP = confusion_matrix(true_labels, predictions).ravel()\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.88      0.86      4987\n",
      "         pos       0.88      0.83      0.85      5013\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwRhjTJH/DzS9L9B7EH2XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "true_labels_bin = [1 if x == 'pos' else 0 for x in true_labels]\n",
    "predictions_bin = [1 if x == 'pos' else 0 for x in predictions]\n",
    "fpr, tpr, thresholds = roc_curve(true_labels_bin, model.predict_proba(X_test)[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr);\n",
    "plt.plot((0,1),(0,1),'--k');\n",
    "plt.xlabel('false positive rate');\n",
    "plt.ylabel('true positive rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285819572140308"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(true_labels_bin, model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "\n",
    "1. First of all the precision and recall numbers calculated using the `confusion_matrix` method and using the `classification_report` are more or less the same. \n",
    "2. In the ROC curve we can see that there are many true positives and not many false positives with the given threshold. The area under the curve is 0.93. If there would have been more false positives with probability > threshold, the curve would have started leaning towards right at the beginning, reducing the area under the curve.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) 4(b) Imbalanced training data\n",
    "rubric={reasoning:1} \n",
    "\n",
    "1. Split (`X_binary`, `imdb_df.label`) into train (80%) and test (20%). Now take a subset of the training data so that you only retain 10% examples with `pos` label but keep 100% of the examples with `neg` label. \n",
    "2. Train Bernoulli Naive Bayes algorithm on this imbalanced train set.\n",
    "3. Get precision and recall numbers using [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) on the test portion (which won't be imbalanced). \n",
    "4. Compare these numbers with precision and recall numbers in 4(a)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Split (`X_binary`, `imdb_df.label`) into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_binary, \n",
    "                                                    imdb_df.label, \n",
    "                                                    test_size = 0.20, \n",
    "                                                    random_state = 12)\n",
    "\n",
    "# Create a dataframe from the sparse feature matrix and the label\n",
    "X_train_df = pd.DataFrame(X_train.toarray())\n",
    "X_train_df['label'] = y_train\n",
    "\n",
    "# Get positive and negative examples from the training data\n",
    "X_train_df_pos = X_train_df[X_train_df['label'] == 'pos']\n",
    "X_train_df_neg = X_train_df[X_train_df['label'] == 'neg']\n",
    "\n",
    "# Take only 10% of the positive examples\n",
    "X_train_df_pos_small = X_train_df_pos.sample(frac = 0.10) \n",
    "\n",
    "# Create a new dataframe with 10% positive examples and all of the negative examples. \n",
    "X_train_small_df = pd.concat([X_train_df_pos_small,X_train_df_neg])\n",
    "\n",
    "# Create X_train and y_train from the new dataframe\n",
    "y_train_small = X_train_small_df['label']\n",
    "X_train_small = X_train_small_df.loc[:, X_train_small_df.columns != 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Train BernoulliNB with the smaller X_train and y_train\n",
    "model = BernoulliNB().fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.50      0.98      0.66      4987\n",
      "         pos       0.65      0.04      0.07      5013\n",
      "\n",
      "   micro avg       0.51      0.51      0.51     10000\n",
      "   macro avg       0.58      0.51      0.37     10000\n",
      "weighted avg       0.58      0.51      0.37     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "The accuracies are markedly worse compared to 4(a). Since there are not many instances of positive reviews in the training data, it seems like the classifier is classifying most of the reviews as `neg`; the recall of `neg` class is very high (0.97) whereas the recall of `pos` class is very low (0.05). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
